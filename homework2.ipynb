{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:17:16.819137Z",
     "start_time": "2021-11-26T00:17:16.751838Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#импортируем всего да побольше\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T20:35:52.090333Z",
     "start_time": "2021-11-25T20:35:51.940468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T20:49:12.545987Z",
     "start_time": "2021-11-25T20:49:12.529001Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция для того, чтобы из разделовского токенизатора вытаскивать только текст\n",
    "razdel_tokenizer = lambda doc: [t.text for t in list(tokenize(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:01:34.710026Z",
     "start_time": "2021-11-25T21:01:34.651167Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize():\n",
    "    train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "    train.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "    y = train.toxic.values\n",
    "    y_test = test.toxic.values\n",
    "    vectorizer = CountVectorizer()\n",
    "    razdel_vectorizer = CountVectorizer(tokenizer = razdel_tokenizer)\n",
    "    return vectorizer, razdel_vectorizer, y_test, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:14:27.139547Z",
     "start_time": "2021-11-25T21:14:27.117551Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNeighbors(vectorizer, y_test, y):\n",
    "    X = vectorizer.fit_transform(train.comment)\n",
    "    X_test = vectorizer.transform(test.comment) \n",
    "    clf = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "    clf.fit(X, y)\n",
    "    preds = clf.predict(X_test)\n",
    "    return precision_recall_fscore_support(y_test, preds, average='weighted')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:18:11.966691Z",
     "start_time": "2021-11-25T21:17:38.011170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "эксперимент  1\n",
      "precision, recall, fscore: \n",
      "default: \n",
      "0.5545272976620662 0.6525658807212206 0.5697133992235924\n",
      "razdel: \n",
      "0.5597823400236488 0.6560332871012483 0.5717941917856686\n",
      "\n",
      "\n",
      "\n",
      "эксперимент  2\n",
      "precision, recall, fscore: \n",
      "default: \n",
      "0.561895432823539 0.6435506241331485 0.565267309903884\n",
      "razdel: \n",
      "0.5442609137387915 0.6255201109570042 0.558492279825164\n",
      "\n",
      "\n",
      "\n",
      "эксперимент  3\n",
      "precision, recall, fscore: \n",
      "default: \n",
      "0.5538334462197032 0.636615811373093 0.5747162747998021\n",
      "razdel: \n",
      "0.5690072663424784 0.6463245492371706 0.5846398662678697\n",
      "\n",
      "\n",
      "\n",
      "эксперимент  4\n",
      "precision, recall, fscore: \n",
      "default: \n",
      "0.5293835429050024 0.6192787794729542 0.5206211532023383\n",
      "razdel: \n",
      "0.49979480693522016 0.6130374479889042 0.5084242793745795\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "while x<=4:\n",
    "    print ('эксперимент ', x)\n",
    "    print('precision, recall, fscore: ')\n",
    "    vectorizer, razdel_vectorizer, y_test, y = vectorize()\n",
    "    print('default: ')\n",
    "    precision,recall,fscore,support=KNeighbors(vectorizer, y_test, y )\n",
    "    print(precision,recall,fscore)\n",
    "    print('razdel: ')\n",
    "    precision1,recall1,fscore1,support1 =KNeighbors(razdel_vectorizer, y_test, y )\n",
    "    print(precision1,recall1,fscore1)\n",
    "    print('\\n\\n')\n",
    "    x+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T20:46:27.159834Z",
     "start_time": "2021-11-25T20:46:26.422708Z"
    }
   },
   "source": [
    "В целом, 4 эксперимента показывают не очень большую разницу между двумя токенайзерами, в которой дефолтный токенизатор показывает себя лучше. Однако, судя по незначительной разнице в метриках то в одну, то в другую сторону, эти результаты практически равнозначны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:55:28.292943Z",
     "start_time": "2021-11-25T18:55:28.249470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\" width=\"600\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg\",\n",
    "     width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:18:17.929223Z",
     "start_time": "2021-11-25T21:18:17.916221Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#заводим массив с данными из таблицы\n",
    "array = [[1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0], [3, 0 , 1, 1, 0, 0], [1, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:18:23.274294Z",
     "start_time": "2021-11-25T21:18:23.213297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 я  ты  и  только  не  он\n",
       "я и ты           1   1  1       0   0   0\n",
       "ты и я           1   1  1       0   0   0\n",
       "я, я и только я  3   0  1       1   0   0\n",
       "только не я      1   0  0       1   1   0\n",
       "он               0   0  0       0   0   1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(array, columns = ['я', 'ты', 'и', 'только', 'не', 'он'], index = ['я и ты','ты и я','я, я и только я', 'только не я', 'он'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:18:38.612327Z",
     "start_time": "2021-11-25T21:18:38.401492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        я        ты         и    только        не   он\n",
       "я и ты           0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "ты и я           0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "я, я и только я  0.600000  0.000000  0.200000  0.200000  0.000000  0.0\n",
       "только не я      0.333333  0.000000  0.000000  0.333333  0.333333  0.0\n",
       "он               0.000000  0.000000  0.000000  0.000000  0.000000  1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#нормализуем таблицу\n",
    "norm_table = table.apply(lambda x: x/ x.sum(), axis = 1)\n",
    "norm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T21:20:04.722246Z",
     "start_time": "2021-11-25T21:20:04.606675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.058146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04437</td>\n",
       "      <td>0.079588</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.132647</td>\n",
       "      <td>0.23299</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        я        ты        и    только       не       он\n",
       "я и ты           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
       "ты и я           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
       "я, я и только я  0.058146  0.000000  0.04437  0.079588  0.00000  0.00000\n",
       "только не я      0.032303  0.000000  0.00000  0.132647  0.23299  0.00000\n",
       "он               0.000000  0.000000  0.00000  0.000000  0.00000  0.69897"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество документов\n",
    "N = len(table)\n",
    "frame = {}\n",
    "# применим формулу к каждой колонке\n",
    "for col in table.columns:\n",
    "    df = len(table[col][table[col]!=0])\n",
    "    series = norm_table[col].apply(lambda x: x*np.log10(N/df))\n",
    "    frame[col] = series\n",
    "result = pd.DataFrame(frame)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:10:27.675023Z",
     "start_time": "2021-11-25T22:10:27.636655Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True, random_state = 32)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:15:45.202863Z",
     "start_time": "2021-11-25T22:15:36.369986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620751341681573"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=7000, min_df= 8, max_df=0.6, ngram_range=(1, 2), tokenizer= razdel_tokenizer, stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = LogisticRegression(C=0.1,solver='lbfgs', class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds1 = clf.predict(X_test)\n",
    "probas1 = clf.predict_proba(X_test)\n",
    "f1_score(y_test, preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:15:52.904715Z",
     "start_time": "2021-11-25T22:15:45.300699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7527527527527527"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000,min_df=5, max_df=0.6, ngram_range=(1, 2),tokenizer=razdel_tokenizer)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = MultinomialNB(fit_prior=False, alpha=1.2)\n",
    "clf.fit(X, y)\n",
    "preds2 = clf.predict(X_test)\n",
    "probas2 = clf.predict_proba(X_test)\n",
    "f1_score(y_test, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:19:04.350402Z",
     "start_time": "2021-11-25T22:19:04.312288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_toxic(probas):\n",
    "    probas = [p[1] for p in probas]\n",
    "    test['probas'] = probas\n",
    "    res_df = test.sort_values(by = 'probas', ascending = False)[:10]\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "    for i in range(10):\n",
    "        print('toxic:', res_df.loc[i].toxic)\n",
    "        print('comment: ', res_df.loc[i].comment)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:19:05.355897Z",
     "start_time": "2021-11-25T22:19:05.148169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer + LogisticRegression: \n",
      "toxic: 1.0\n",
      "comment:  АЛЛО БЛЯДЬ АБУ ТЫ Ч ОХУЕЛ? ВЫГОНЯЙ НАХУЙ СВОЕГО ПОДЗАЛУПНОГО ДРУЖКА ВАРЛАМОВА НАХУЙ ИЗ Б ЭТА ХУЙНЯ ЗАЕБАЛА В 5 ТРЕДОВ БЛЯДЬ НА ГЛАВНОЙ ВИСЕТЬ, БАНЫЙ ТВОЙ РОТ ДЫРЯВЫЙ БЛЯДЬ, ПРОДАЖНАЯ МРАЗЬ!\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Какие блять передергивания? Ты дебил блять зашел на шок-доску и удивляешься что над тобой издеваются. Тут нет твоих друзей, рачье тупорылое, тут тебя все ненавидят. Как же печет от таких необучаемых ебланов. Ты ковбой, твою жену ебут где-то нахуй, а дети гибнут на Украине. Понял, быдло ты ебаное?\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  А нахуй ты тут персональный чатик устроил, дегенерат? Или ты сейчас каждому работяге, который зайдет в твой обоссаный тред будешь бежать доказывать в чем он не прав и как нужно сделать шоб было всё нормально ? Проблема травлятредов была озвучена ещё задолго до того, как ты и тебе подобные, кукарекающие про школьников, срыватели покровов засунул на этот сайт свой немытый ебальник. Правда для этого люди не разводили шитпостинг на овер 100 постов с переливанием из пустого в порожнее. b для этого подходит идеально - вот там со своими братьями по разуму и разводи драму, хоть на несколько тредов. Я кончил и закурил, можешь теперь маршировать нахуй.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Что за ебанутая хуйня? Чувак просто ходил с маской и раздвал какую-то хуйню, на которую всем похуй и его хотят набутылить? Что за пиздец?\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Злобный дегенерат и педераст, здохший от передоза в говне и блевотине, от которого даже отец отрекся, вновь возвращается, чтобы доводить детей до анальных колик. Суть такова, что на телефон поступает видеодозвон, где кровожадный педофил, видать только слезший с кукана Сатаны, угрожает придти к вам в спальню в три часа ночи и сделать с вами ЭТО под незабвенные истерические взгвизгивания йи-хи ! Вся Северная Америка в панике! Оперативные сводки доносят, что форс начался в Мексике и распространился на весь континент! Общественность трясется от ужаса и негодует! Невзирая на заверения полиции, что это всего лишь безобидный форс и никто не собирается насиловать вашу спидозную жопу, граждане не верят и вооружаются на случай всякого, намереваясь встретить инфернального педофила хэдшотом в ебало. Так же распространяются сертифицированные памятки об анальной угрозе со стороны сдохшего баребаки. Так что будьте бдительны, может быть в это самое время Майкл Джексон угрожает изнасиловать и вашего сына тоже! А может, он готовиться изнасиловать вас!\n",
      "\n",
      "toxic: 0.0\n",
      "comment:  Делай людям добро - и тебе всегда будет больно и стыдно. Унижай, бей, обманывай - и будешь уважаемым человеком, тебе будут кланяться и звать по имени-отчеству. Что тебе больше нравится - выбирай сам. Выбрал боль и стыд - спасибо, дорогой. Мне меньше достанется.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  предлагаю пидорнуть хохлов, хохлы не имеют отношения к политике постят всякую хуйню безграмотную и блевотную\n",
      "\n",
      "TfidfVectorizer + MultinomialNB: \n",
      "toxic: 1.0\n",
      "comment:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Какие блять передергивания? Ты дебил блять зашел на шок-доску и удивляешься что над тобой издеваются. Тут нет твоих друзей, рачье тупорылое, тут тебя все ненавидят. Как же печет от таких необучаемых ебланов. Ты ковбой, твою жену ебут где-то нахуй, а дети гибнут на Украине. Понял, быдло ты ебаное?\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  АЛЛО БЛЯДЬ АБУ ТЫ Ч ОХУЕЛ? ВЫГОНЯЙ НАХУЙ СВОЕГО ПОДЗАЛУПНОГО ДРУЖКА ВАРЛАМОВА НАХУЙ ИЗ Б ЭТА ХУЙНЯ ЗАЕБАЛА В 5 ТРЕДОВ БЛЯДЬ НА ГЛАВНОЙ ВИСЕТЬ, БАНЫЙ ТВОЙ РОТ ДЫРЯВЫЙ БЛЯДЬ, ПРОДАЖНАЯ МРАЗЬ!\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Какие же хохлы революционеры, пиздец просто\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Целью встречи стали переговоры о сохранении поставок газа А что, у него есть полномочия вести такие переговоры? Сука блядский цирк. Какие же хохлы дегенераты, пиздец просто\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  Да мы поняли что ты пидорьё ебаное, поляк наверное. Иди уроки выучи, портфель собери, че ты.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  предлагаю пидорнуть хохлов, хохлы не имеют отношения к политике постят всякую хуйню безграмотную и блевотную\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  залетуха плиз, если ты так любишь покой, то ты бы вспомнил лето и осень, когда даун на модере тер АБСОЛЮТНО все, а так ты просто даун который очередной раз разжигаешь срач и тебе похуй на реакшены, главное просто повыебываться и посрать.\n",
      "\n",
      "toxic: 1.0\n",
      "comment:  КОГДА Я ВИДУ ВАТНИКА, Я ЕГО ПОСЫЛАЮ! ТЫ ВАТНИК, ИДИ НА ХУЙ! ОБОССАЛ ВАШ ПЕТУШИНЫЙ ЗАГОН!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizer + LogisticRegression: ')\n",
    "clf1 = find_toxic(probas1)\n",
    "print('TfidfVectorizer + MultinomialNB: ')\n",
    "clf2 = find_toxic(probas2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T22:19:51.638143Z",
     "start_time": "2021-11-25T22:19:51.551246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic_x</th>\n",
       "      <th>probas_x</th>\n",
       "      <th>toxic_y</th>\n",
       "      <th>probas_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АЛЛО БЛЯДЬ АБУ ТЫ Ч ОХУЕЛ? ВЫГОНЯЙ НАХУЙ СВОЕГ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие блять передергивания? Ты дебил блять заш...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Блядь абу нахуй ссылай этих дегенератов в фаг,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>предлагаю пидорнуть хохлов, хохлы не имеют отн...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic_x  probas_x  \\\n",
       "0  АЛЛО БЛЯДЬ АБУ ТЫ Ч ОХУЕЛ? ВЫГОНЯЙ НАХУЙ СВОЕГ...      1.0  0.999889   \n",
       "1  Какие блять передергивания? Ты дебил блять заш...      1.0  0.998683   \n",
       "2  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. ...      1.0  0.998444   \n",
       "3  Блядь абу нахуй ссылай этих дегенератов в фаг,...      1.0  0.993369   \n",
       "4  предлагаю пидорнуть хохлов, хохлы не имеют отн...      1.0  0.988709   \n",
       "\n",
       "   toxic_y  probas_y  \n",
       "0      1.0  0.996844  \n",
       "1      1.0  0.997152  \n",
       "2      1.0  0.998899  \n",
       "3      1.0  0.993956  \n",
       "4      1.0  0.986386  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.merge(clf2, how = 'inner', on ='comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из 10 текстов сопало 5 -- мне кажется, это неплохой результат. Причем все совпавшие тексты являются токсичными,и из всех результатов классификатора не токичным оказался только один комментарий: \"Делай людям добро - и тебе всегда будет больно и стыдно. Унижай, бей, обманывай - и будешь уважаемым человеком, тебе будут кланяться и звать по имени-отчеству. Что тебе больше нравится - выбирай сам. Выбрал боль и стыд - спасибо, дорогой. Мне меньше достанется.\" Возможно, из-за слов \"Унижай, бей, обманывай - и будешь уважаемым человеком\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:36:29.982918Z",
     "start_time": "2021-11-26T00:36:19.677376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хохлы\n",
      "хохлов\n",
      "тебе\n",
      "дебил\n",
      "нахуй\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True, random_state = 27)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "vectorizer = CountVectorizer(max_features=7000, min_df= 8, max_df=0.6, ngram_range=(1, 2), tokenizer= razdel_tokenizer, stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = LogisticRegression(C=0.1,solver='lbfgs', class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "importance = clf.coef_\n",
    "words ={value:key for key, value in vectorizer.vocabulary_.items()}\n",
    "idx = importance.argsort()\n",
    "for i in idx[0][:-6:-1]:\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:36:09.859714Z",
     "start_time": "2021-11-26T00:36:01.055790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тебе\n",
      "хохлы\n",
      "очень\n",
      "хохлов\n",
      "нахуй\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=7000, min_df= 8, max_df=0.6, ngram_range=(1, 2), tokenizer= lambda doc: [token for token in razdel_tokenizer(doc) if token not in string.punctuation], stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "importance = clf.feature_importances_\n",
    "words ={value:key for key, value in vectorizer.vocabulary_.items()}\n",
    "idx = importance.argsort()\n",
    "for i in idx[:-6:-1]:\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:36:19.156458Z",
     "start_time": "2021-11-26T00:36:09.990793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это\n",
      "тебе\n",
      "просто\n",
      "хохлы\n",
      "хохлов\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000,min_df=5, max_df=0.6, ngram_range=(1, 2),tokenizer=lambda doc: [token for token in razdel_tokenizer(doc) if token not in string.punctuation and token.isalpha()],  stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = MultinomialNB(fit_prior=False, alpha=1.2)\n",
    "clf.fit(X, y)\n",
    "importance = clf.coef_\n",
    "words ={value:key for key, value in vectorizer.vocabulary_.items()}\n",
    "idx = importance.argsort()\n",
    "for i in idx[0][:-6:-1]:\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:41:08.865972Z",
     "start_time": "2021-11-26T00:41:01.689448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "просто\n",
      "хохлы\n",
      "хохлов\n",
      "почему\n",
      "нахуй\n"
     ]
    }
   ],
   "source": [
    "# я не знаю, являются ли \"это\" и \"тебе\" стоп-словами, если да, то:\n",
    "stop_words=stopwords.words('russian')\n",
    "stop_words.extend(['это','тебе'])\n",
    "vectorizer = TfidfVectorizer(max_features=5000,min_df=5, max_df=0.6, ngram_range=(1, 2),tokenizer=lambda doc: [token for token in razdel_tokenizer(doc) if token not in string.punctuation and token.isalpha()],  stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = MultinomialNB(fit_prior=False, alpha=1.2)\n",
    "clf.fit(X, y)\n",
    "importance = clf.coef_\n",
    "words ={value:key for key, value in vectorizer.vocabulary_.items()}\n",
    "idx = importance.argsort()\n",
    "for i in idx[0][:-6:-1]:\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T00:34:21.998384Z",
     "start_time": "2021-11-26T00:34:13.755278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тебе\n",
      "нахуй\n",
      "хохлы\n",
      "хохлов\n",
      "блядь\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=7000, min_df= 8, max_df=0.6, ngram_range=(1, 2), tokenizer= lambda doc: [token for token in razdel_tokenizer(doc) if token not in string.punctuation], stop_words=stopwords.words('russian'))\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=20, )\n",
    "clf.fit(X, y)\n",
    "importance = clf.feature_importances_\n",
    "words ={value:key for key, value in vectorizer.vocabulary_.items()}\n",
    "idx = importance.argsort()\n",
    "for i in idx[:-6:-1]:\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, основными фичами считаются слова \"хохлы\", \"хохлов\", \"нахуй\" для всех классификаторов.\n",
    "Можно убирать слова в духе \"почему\", но я не уверена, что это корректно. Вполне возможно, что большая часть токсик-предложений начинаются именно с почему. И, как мне кажется, это все же не стоп-слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
